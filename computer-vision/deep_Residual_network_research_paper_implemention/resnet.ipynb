{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e107eda6",
   "metadata": {},
   "source": [
    "# deep residual network "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc88f2de",
   "metadata": {},
   "source": [
    "what this paper is all about is how to increase the depth of the network without harm the preformance \n",
    "the authors say that when you increase the depth you will face serious problem with vanishing and exploding gradients so they manges to deal with that \n",
    "\n",
    "they considered a shallow network and deeper one as counterpart which you add more layers into the deeper one and they claimed that the solution by construction to the deeper model :  the added layers are identity mapping \n",
    "\n",
    "the expected behavior that the new model produce no higher training error but what was surprising that it give them better solutions \n",
    "\n",
    "so how they managed that ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d955e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense , Conv2D , Add ,ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cae414",
   "metadata": {},
   "source": [
    "### who the model work \n",
    "The formulation of F(x) + x  can be realized by feedforward neural networks with “shortcut connections” \n",
    "what is shortcut connections ? \n",
    "Shortcut connections are those skipping one or more layers. In our case, the shortcut connections simply\n",
    "perform identity mapping, and their outputs are added to the outputs of the stacked layers  Identity shortcut connections add neither extra parameter nor computational complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b660fe42",
   "metadata": {},
   "source": [
    "### model description \n",
    "\n",
    "so they described two version of the network one which contain about 34 layer and another one which 152 we will implement both \n",
    "we will first start with the simple one \n",
    "\n",
    "### the Architectures \n",
    "the authors were inspired by the VGG architectures so the architectures consist of blocks each block contain two conv layer with (3,3) kernal size and the architectures follow simple rule which when we halved the feature map (stride = 2) we double the number of filter \n",
    "\n",
    "### problem \n",
    "tiny problem we will face that to add two layers they should have the same dimentions so this will work fine at first but \n",
    "when we set the strides = 2 and double the filter number this we cause error so the authors proposed two solution \n",
    "- first one to use zero padding \n",
    "- second to use conv layer with kernal(1,1 ) in the shortcut layer to match the shape of the stacked layer and this the solution they used to deal with that  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "649b4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init residual_block class \n",
    "class residual_block(tf.keras.Model) : \n",
    "    def __init__(self , n_filters , kernal_size,strides   ) : \n",
    "        super(residual_block , self).__init__()\n",
    "        # define the two conv layers \n",
    "        self.conv_res_1 = Conv2D(n_filters , (kernal_size,kernal_size) , strides = (strides,strides) , padding = 'same' , activation='relu') \n",
    "        self.conv_res_2 = Conv2D(n_filters , (kernal_size,kernal_size) , strides = (1,1) , padding = 'same' ) \n",
    "        #define the short cut conv with (1,1) kernal to match the shape \n",
    "        self.shourt_cut_conv = Conv2D(n_filters , (1,1) , strides = (strides,strides)  , padding = 'valid') \n",
    "        self.add = Add() \n",
    "        self.relu = ReLU() \n",
    "    def call(self, inputs ) :\n",
    "        # keep the input \n",
    "        X_short_cut =inputs\n",
    "        # pass the input throw the conv layers \n",
    "        X = self.conv_res_1(inputs)\n",
    "        X = self.conv_res_2(X) \n",
    "        # match the stacked layers shape\n",
    "        connection = self.shourt_cut_conv(X_short_cut)\n",
    "        # add the two layers \n",
    "        addtion = self.add([X , connection])\n",
    "        return self.relu(addtion) \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33dd8a0",
   "metadata": {},
   "source": [
    "### the model \n",
    "- they start the model with conv layer \n",
    "- followed by maxpooling layer \n",
    "- they used 16 residul block \n",
    "- then average pooling and dense layer with number of output classes \n",
    "\n",
    "so we will loop to define the 16 block by using this little loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b6c26f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class res_model(tf.keras.Model) : \n",
    "    def __init__(self , num_classes) : \n",
    "        super(res_model ,self).__init__() \n",
    "        self.n_filter = 64\n",
    "        self.first_layer = Conv2D(64 , 7 , strides=(2,2) , padding ='same' , activation ='relu')\n",
    "        self.max_pool = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))\n",
    "        \n",
    "        # loop throw the num of blocks and use class var object to define the blocks \n",
    "        for i in range(1, 17) : \n",
    "            # in the paper they halved the feature map and doubled the filter size three times in [4,8,14] block number\n",
    "            if i in [4, 8 ,14] :\n",
    "                # we double filter number \n",
    "                self.n_filter *=  2 \n",
    "                # we halved the feature map by setting the strides  = 2 \n",
    "                vars(self)[f'block_{i}'] = residual_block(self.n_filter , 3, strides = 2 )\n",
    "            else : \n",
    "                vars(self)[f'block_{i}'] = residual_block(self.n_filter , 3, strides = 1 )\n",
    "                \n",
    "        self.avg_pool = tf.keras.layers.AveragePooling2D()\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.out = Dense(num_classes , activation ='softmax')\n",
    "    \n",
    "    def call(self, inputs )  : \n",
    "        # pass the input throw the first layer \n",
    "        X = self.first_layer(inputs)\n",
    "        X = self.max_pool(X)\n",
    "        # pass the inputs throw the blocks \n",
    "        for i in range(1,17)  :\n",
    "            block_i = vars(self)[f'block_{i}']\n",
    "            X = block_i(X)\n",
    "        X = self.avg_pool(X)\n",
    "        X = self.flat(X)\n",
    "        return self.out(X)     \n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4615fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = res_model(# number of classes  )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9b949b",
   "metadata": {},
   "source": [
    "### model training \n",
    "\n",
    "- they used SGD optimizer \n",
    "- ReduceLROnPlateau callback \n",
    "- categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "852d823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plateau_callback =  tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b440a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='sgd' , loss ='categorical_crossentropy' , metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f013342",
   "metadata": {},
   "source": [
    "## second version \n",
    "this version is really deep so they made some changes to the Architectures \n",
    "this time each block consist of three conv layers  : \n",
    "- first and last layer with (1,1) kernal shape to control the shape of the data \n",
    "- second layer act as bottle neck with kernal (3,3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "503436a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deep_residual_block(tf.keras.Model) : \n",
    "    def __init__(self , n_filters  , kernal_size,strides   ) : \n",
    "        super(deep_residual_block , self).__init__()\n",
    "        # define the conv layers this time n_filters is list because it hasn,t have to be the same number \n",
    "        self.conv_res_1 = Conv2D(n_filters[0] , (1,1) , strides = (strides,strides) , padding = 'valid' , activation='relu') \n",
    "        self.conv_res_2 = Conv2D(n_filters[1] , (kernal_size,kernal_size) , strides = (1,1) , padding = 'same' , activation ='relu') \n",
    "        self.conv_res_3 = Conv2D(n_filters[2], (1,1) , strides = (1,1) , padding = 'valid' )\n",
    "        # we define conv layer to match the shape of the stacked model and it has the same filters as the third conv layer \n",
    "        self.shourt_cut_conv = Conv2D(n_filters[2] , (1,1) , strides = (strides,strides)  , padding = 'valid') \n",
    "        self.add = Add() \n",
    "        self.relu = ReLU() \n",
    "    def call(self, inputs ) :\n",
    "        X_short_cut =inputs\n",
    "        X = self.conv_res_1(inputs)\n",
    "        X = self.conv_res_2(X) \n",
    "        X = self.conv_res_3(X)\n",
    "        connection = self.shourt_cut_conv(X_short_cut)\n",
    "        addtion = self.add([X , connection])\n",
    "        return self.relu(addtion) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e0307",
   "metadata": {},
   "source": [
    "### the model \n",
    "\n",
    "the model almost will stay the same we will just define filter number as a lise \n",
    "and in the paper they did not say when they halved the feature map so i set it like that \n",
    "when the i can be divided by 20  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "48df7256",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deep_res_model(tf.keras.Model) : \n",
    "    def __init__(self , num_classes) : \n",
    "        super(deep_res_model ,self).__init__() \n",
    "        self.n_filter = [64 ,64 ,128]\n",
    "        self.first_layer = Conv2D(64 , 7 , strides=(2,2) , padding ='same' , activation ='relu')\n",
    "        self.max_pool = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))\n",
    "        for i in range(1,51 ) : \n",
    "            if i % 20 == 0  :\n",
    "                self.n_filter *=  2 \n",
    "                vars(self)[f'block_{i}'] = deep_residual_block(self.n_filter , 3, strides = 2 )\n",
    "            else : \n",
    "                vars(self)[f'block_{i}'] = deep_residual_block(self.n_filter , 3, strides = 1 )\n",
    "        self.avg_pool = tf.keras.layers.AveragePooling2D()\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.out = Dense(num_classes , activation ='softmax')\n",
    "    \n",
    "    def call(self, inputs )  : \n",
    "        X = self.first_layer(inputs)\n",
    "        X = self.max_pool(X)\n",
    "        for i in range(1,10)  :\n",
    "            block_i = vars(self)[f'block_{i}']\n",
    "            X = block_i(X)\n",
    "        X = self.avg_pool(X)\n",
    "        X = self.flat(X)\n",
    "        return self.out(X)     \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761398c7",
   "metadata": {},
   "source": [
    "## conclusion \n",
    "\n",
    "this all about residual network this paper is accully easy to read and you should do and you can search for images that illustrate the Architectures of the model \n",
    "\n",
    "you can try this model but make sure that the height and width of the image big enough to fit the model to avoid errors or you can decrease the number of blocks "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
